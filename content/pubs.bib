@article{Howard2017,
  author    = {Andrew G. Howard and
               Menglong Zhu and
               Bo Chen and
               Dmitry Kalenichenko and
               Weijun Wang and
               Tobias Weyand and
               Marco Andreetto and
               Hartwig Adam},
  title     = {MobileNets: Efficient Convolutional Neural Networks for Mobile Vision
               Applications},
  journal   = {CoRR},
  volume    = {abs/1704.04861},
  year      = {2017},
  url       = {http://arxiv.org/abs/1704.04861},
  archivePrefix = {arXiv},
  eprint    = {1704.04861},
  timestamp = {Mon, 13 Aug 2018 16:46:35 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/HowardZCKWWAA17.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{Gal2016,
    author = {Gal, Yarin and Ghahramani, Zoubin},
    title = {Dropout as a Bayesian Approximation: Representing Model Uncertainty in Deep Learning},
    year = {2016},
    publisher = {JMLR.org},
    abstract = {Deep learning tools have gained tremendous attention in applied machine learning. However such tools for regression and classification do not capture model uncertainty. In comparison, Bayesian models offer a mathematically grounded framework to reason about model uncertainty, but usually come with a prohibitive computational cost. In this paper we develop a new theoretical framework casting dropout training in deep neural networks (NNs) as approximate Bayesian inference in deep Gaussian processes. A direct result of this theory gives us tools to model uncertainty with dropout NNs - extracting information from existing models that has been thrown away so far. This mitigates the problem of representing uncertainty in deep learning without sacrificing either computational complexity or test accuracy. We perform an extensive study of the properties of dropout's uncertainty. Various network architectures and nonlinearities are assessed on tasks of regression and classification, using MNIST as an example. We show a considerable improvement in predictive log-likelihood and RMSE compared to existing state-of-the-art methods, and finish by using dropout's uncertainty in deep reinforcement learning.},
    booktitle = {Proceedings of the 33rd International Conference on International Conference on Machine Learning - Volume 48},
    pages = {1050-1059},
    numpages = {10},
    location = {New York, NY, USA},
    series = {ICML'16},
    url = {https://dl.acm.org/doi/10.5555/3045390.3045502}
}

@inproceedings{Lakshminarayanan2017,
    author = {Lakshminarayanan, Balaji and Pritzel, Alexander and Blundell, Charles},
    title = {Simple and Scalable Predictive Uncertainty Estimation Using Deep Ensembles},
    year = {2017},
    isbn = {9781510860964},
    publisher = {Curran Associates Inc.},
    address = {Red Hook, NY, USA},
    abstract = {Deep neural networks (NNs) are powerful black box predictors that have recently achieved impressive performance on a wide spectrum of tasks. Quantifying predictive uncertainty in NNs is a challenging and yet unsolved problem. Bayesian NNs, which learn a distribution over weights, are currently the state-of-the-art for estimating predictive uncertainty; however these require significant modifications to the training procedure and are computationally expensive compared to standard (non-Bayesian) NNs. We propose an alternative to Bayesian NNs that is simple to implement, readily parallelizable, requires very little hyperparameter tuning, and yields high quality predictive uncertainty estimates. Through a series of experiments on classification and regression benchmarks, we demonstrate that our method produces well-calibrated uncertainty estimates which are as good or better than approximate Bayesian NNs. To assess robustness to dataset shift, we evaluate the predictive uncertainty on test examples from known and unknown distributions, and show that our method is able to express higher uncertainty on out-of-distribution examples. We demonstrate the scalability of our method by evaluating predictive uncertainty estimates on ImageNet.},
    booktitle = {Proceedings of the 31st International Conference on Neural Information Processing Systems},
    pages = {6405-6416},
    numpages = {12},
    location = {Long Beach, California, USA},
    series = {NIPS'17},
    url = {https://dl.acm.org/doi/10.5555/3295222.3295387}
}

@article{Sequ2019,
  author    = {Mattia Seg{\`{u}} and
               Antonio Loquercio and
               Davide Scaramuzza},
  title     = {A General Framework for Uncertainty Estimation in Deep Learning},
  journal   = {CoRR},
  volume    = {abs/1907.06890},
  year      = {2019},
  url       = {http://arxiv.org/abs/1907.06890},
  archivePrefix = {arXiv},
  eprint    = {1907.06890},
  timestamp = {Tue, 23 Jul 2019 10:54:22 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1907-06890.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}